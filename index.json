[{"content":"Teleport has a strong RBAC system that allows to grant access to specific resources.\nIn order to setup your environment, You need to do some preperations:\nDefine what are the Groups in your organization Define which access each group needs, For example:\nDevelopers group needs access to Grafana and server Superset Decide how to label each server / resource, and assign the labels to each resource Deinfe the policy that grants the access to the resources kind: role version: v5 metadata: name: Developers description: Developers Team Role spec: allow: logins: [\u0026#39;admin\u0026#39;] node_labels: \u0026#39;type\u0026#39;: \u0026#39;Grafana\u0026#39; \u0026#39;type\u0026#39;: \u0026#39;Superset\u0026#39; ","permalink":"https://omers.github.io/docs/teleport/access-and-authorization/","summary":"Teleport has a strong RBAC system that allows to grant access to specific resources.\nIn order to setup your environment, You need to do some preperations:\nDefine what are the Groups in your organization Define which access each group needs, For example:\nDevelopers group needs access to Grafana and server Superset Decide how to label each server / resource, and assign the labels to each resource Deinfe the policy that grants the access to the resources kind: role version: v5 metadata: name: Developers description: Developers Team Role spec: allow: logins: [\u0026#39;admin\u0026#39;] node_labels: \u0026#39;type\u0026#39;: \u0026#39;Grafana\u0026#39; \u0026#39;type\u0026#39;: \u0026#39;Superset\u0026#39; ","title":"Teleport Access and Authorization"},{"content":"Mining health data can lead to faster medical decisions, improvement in the quality of treatment, disease prevention, reduced cost, and it drives innovative solutions within the healthcare sector.\nHowever, health data is highly sensitive and subject to regulations such as the General Data Protection Regulation (GDPR), which aims to ensure patient\u0026rsquo;s privacy.\nAnonymization or removal of patient identifiable information, though the most conventional way, is the first important step to adhere to the regulations and incorporate privacy concerns.\nIn this post, I\u0026rsquo;ll review a Python package created my Microsoft that helps to ensure sensitive data is properly managed and governed.\nIt provides fast identification and anonymization modules for private entities in text and images such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more..\nAllow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions. Embrace extensibility and customizability to a specific business need. Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms. Install pip install presidio-analyzer pip install presidio-anonymizer python -m spacy download en_core_web_lg Sample Code from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine text=\u0026#34;\u0026#34;\u0026#34; PATIENT: JOHN SMITH DOB: 5/5/1955 FILE #: 12345 PHYSICIAN: REFERRING EXAM: MRI ABDOMEN WITH CONTRAST DATE: 1/1/2011 Evaluation of the neck reveals a somewhat heterogeneous but well defined lobulated mass within the superficial lobe of the anterior right parotid gland. The mass demonstrates a rounded focus of signal prolongation with enhancement. The mass measures approximately 0.8 x 0.9 x 0.7 CM (anterior-posterior by transverse by superiorinferior). This appears similar to that noted on the prior CT. The mass just abuts the retromandibular vein, patent and medial to the right parotid duct. The mass is most consistent with a benign pleomorphic adenoma. No leftsided parotid mass is seen. Right and left submandibular glands are unremarkable. The mucosal surfaces of the upper aerodigestive tract appear symmetric and unremarkable. The larynx is intact. The nasopharynx is symmetric without distinct lesion. The tongue and tongue base appear symmetric and unremarkable. The median raphe is midline. The thyroid gland appears symmetric without distinct nodule. No pathologically enlarged lymph nodes are found. The visualized lymph nodes demonstrate no central necrosis or extranodal extension. The right and left faucial tonsil is symmetric and unremarkable. The lingual tonsillar tissue appears symmetric and of normal volume. The posterior nasopharyngeal lymphoid tissue does not appear enlarged. Evaluation of the paranasal sinuses reveals no significant sinus inflammatory disease. No air-fluid levels are noted. The central skull base is intact. The central petrous temporal bones and mastoids remain clear. The visualized base of brain appears unremarkable. Cervical spondylosis is noted, most notable for a broad-based disc bulge and dorsal osteophytic ridge at the C5/6 level with a C6/7 level focal 2 mm central disc protrusion and dorsal osteophytic ridging, resulting in mild central spinal stenosis. Mild foraminal narrowing also evident bilaterally. \u0026#34;\u0026#34;\u0026#34; # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine() # Call analyzer to get results results = analyzer.analyze(text=text,language=\u0026#39;en\u0026#39;) print(results) # Analyzer results are passed to the AnonymizerEngine for anonymization anonymizer = AnonymizerEngine() anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results) print(anonymized_text) The output text: PATIENT: \u0026lt;PERSON\u0026gt;: \u0026lt;DATE_TIME\u0026gt; FILE #: 12345 PHYSICIAN: REFERRING EXAM: MRI ABDOMEN WITH CONTRAST DATE: \u0026lt;DATE_TIME\u0026gt; Marked hydronephrosis and hydroureter are present in the right kidney (series 12 images \u0026lt;DATE_TIME\u0026gt;). Low signal intensity foci in the proximal right ureter (series 6 image 36) likely represents flow related artifact. Possible septations may be present in the distal right ureter (series 12 image 20). CT scan of the abdomen and pelvis with and without contrast is recommended to evaluate for possible stone or distal obstructing lesion. Findings are new since the previous examination. Decreased enhancement of the right kidney in comparison to the left during the arterial phase (series 15 image 35) may reflect a renal compromise. Stable mild \u0026lt;PERSON\u0026gt; is again noted in the left kidney. No mass is identified in the kidneys. No masses seen along the right ureter. Postoperative changes are seen from a distal pancreatectomy and cholecystectomy representing previous \u0026lt;PERSON\u0026gt; procedure. There is dilatation of the pancreatic duct in the body and tail (series 6 images 23-20). No recurrent mass is seen in the pancreas or anastomosis. There is mild prominence of the biliary ducts in the left hepatic lobe (series 7 image 20). No filling defect is seen within the common duct. \u0026lt;PERSON\u0026gt; and adrenal glands are unremarkable. No free fluid or lymphadenopathy seen. No bowel obstruction is identified. Anterior abdominal hernia is again noted containing small bowel without evidence of strangulation (series 7 image 33). There is marked S-shaped scoliosis of the thoracolumbar spine. No metastatic bone lesions are identified. items: [ {\u0026#39;start\u0026#39;: 1296, \u0026#39;end\u0026#39;: 1304, \u0026#39;entity_type\u0026#39;: \u0026#39;PERSON\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;PERSON\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 987, \u0026#39;end\u0026#39;: 995, \u0026#39;entity_type\u0026#39;: \u0026#39;PERSON\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;PERSON\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 764, \u0026#39;end\u0026#39;: 772, \u0026#39;entity_type\u0026#39;: \u0026#39;PERSON\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;PERSON\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 206, \u0026#39;end\u0026#39;: 217, \u0026#39;entity_type\u0026#39;: \u0026#39;DATE_TIME\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;DATE_TIME\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 105, \u0026#39;end\u0026#39;: 116, \u0026#39;entity_type\u0026#39;: \u0026#39;DATE_TIME\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;DATE_TIME\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 20, \u0026#39;end\u0026#39;: 31, \u0026#39;entity_type\u0026#39;: \u0026#39;DATE_TIME\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;DATE_TIME\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;}, {\u0026#39;start\u0026#39;: 10, \u0026#39;end\u0026#39;: 18, \u0026#39;entity_type\u0026#39;: \u0026#39;PERSON\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;PERSON\u0026gt;\u0026#39;, \u0026#39;operator\u0026#39;: \u0026#39;replace\u0026#39;} ] ","permalink":"https://omers.github.io/docs/data/privacy/anonymization/","summary":"Mining health data can lead to faster medical decisions, improvement in the quality of treatment, disease prevention, reduced cost, and it drives innovative solutions within the healthcare sector.\nHowever, health data is highly sensitive and subject to regulations such as the General Data Protection Regulation (GDPR), which aims to ensure patient\u0026rsquo;s privacy.\nAnonymization or removal of patient identifiable information, though the most conventional way, is the first important step to adhere to the regulations and incorporate privacy concerns.","title":"Data Protection and Anonymization"},{"content":"","permalink":"https://omers.github.io/docs/cloud-management/cloud-resources-governance/","summary":"","title":"Cloud Resources Governance"},{"content":"During the lifecycle of a company, we are required to have an assets inventory.\nThe process of having an asset inventory contains few steps.\nCloudQuery As the tool that scrapes AWS and gather all the information, We will use CloudQuery\nTimescaleDB Apache Superset ","permalink":"https://omers.github.io/docs/cloud-management/cloud-resources-dashboards/","summary":"During the lifecycle of a company, we are required to have an assets inventory.\nThe process of having an asset inventory contains few steps.\nCloudQuery As the tool that scrapes AWS and gather all the information, We will use CloudQuery\nTimescaleDB Apache Superset ","title":"Cloud Resources Dashboards"},{"content":"","permalink":"https://omers.github.io/docs/monitoring/cloudquery/","summary":"","title":"Cloudquery"},{"content":"","permalink":"https://omers.github.io/docs/automation/n8n/","summary":"","title":"N8n"},{"content":"This is a one liner on how to create SSL Self signed certificate with OpenSSL\nopenssl req -new -newkey rsa:4096 -days 365 \\ -nodes -x509 -keyout server.key -out server.crt ","permalink":"https://omers.github.io/docs/automation/generate-self-signed-cert/","summary":"This is a one liner on how to create SSL Self signed certificate with OpenSSL\nopenssl req -new -newkey rsa:4096 -days 365 \\ -nodes -x509 -keyout server.key -out server.crt ","title":"OpenSSL Generate self signed certificate"},{"content":"Loki is a datastore optimized for efficiently holding log data.\nThe efficient indexing of log data distinguishes Loki from other logging systems. Unlike other logging systems, a Loki index is built from labels, leaving the original log message unindexed.\nThe Basic native tool to send data to Loki, is Promtail\nA sample config file for Loki might seen like the follows:\nserver: http_listen_port: 0 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: https://your.loki.cluster scrape_configs: - job_name: system static_configs: - targets: - localhost labels: job: varlogs __path__: /var/log/*.log - targets: - localhost labels: job: syslog __path__: /var/log/syslog ","permalink":"https://omers.github.io/docs/monitoring/loki/","summary":"Loki is a datastore optimized for efficiently holding log data.\nThe efficient indexing of log data distinguishes Loki from other logging systems. Unlike other logging systems, a Loki index is built from labels, leaving the original log message unindexed.\nThe Basic native tool to send data to Loki, is Promtail\nA sample config file for Loki might seen like the follows:\nserver: http_listen_port: 0 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: https://your.","title":"Loki Log based metrics a.k.a logs2metrics"},{"content":"Quantiles from histograms 90th percentile request latency over last 5 minutes, for every label dimension:\nhistogram_quantile(0.9, rate(api_duration_seconds_bucket[5m])) Rates of increase for counters Per-second rate of increase, averaged over last 5 minutes: rate(demo_api_request_duration_seconds_count[5m]) Per-second rate of increase, calculated over last two samples in a 1-minute time window irate(demo_api_request_duration_seconds_count[1m]) Absolute increase over last hour: increase(demo_api_request_duration_seconds_count[1h]) Aggregating over time Average within each series over a 5-minute period avg_over_time(go_goroutines[5m]) Get the maximum for each series over a one-day period max_over_time(process_resident_memory_bytes[1d]) Count the number of samples for each series over a 5-minute period count_over_time(process_resident_memory_bytes[5m]) ","permalink":"https://omers.github.io/cheatsheet/prometheus/common-queries/","summary":"Quantiles from histograms 90th percentile request latency over last 5 minutes, for every label dimension:\nhistogram_quantile(0.9, rate(api_duration_seconds_bucket[5m])) Rates of increase for counters Per-second rate of increase, averaged over last 5 minutes: rate(demo_api_request_duration_seconds_count[5m]) Per-second rate of increase, calculated over last two samples in a 1-minute time window irate(demo_api_request_duration_seconds_count[1m]) Absolute increase over last hour: increase(demo_api_request_duration_seconds_count[1h]) Aggregating over time Average within each series over a 5-minute period avg_over_time(go_goroutines[5m]) Get the maximum for each series over a one-day period max_over_time(process_resident_memory_bytes[1d]) Count the number of samples for each series over a 5-minute period count_over_time(process_resident_memory_bytes[5m]) ","title":"Prometheus Common Queries"},{"content":"YOLOv5 🚀 is a family of object detection architectures and models pretrained on the COCO dataset, and represents Ultralytics open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\nThe project source code can be found Here\n","permalink":"https://omers.github.io/docs/ai/yolov/","summary":"YOLOv5 🚀 is a family of object detection architectures and models pretrained on the COCO dataset, and represents Ultralytics open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\nThe project source code can be found Here","title":"YOLO — You only look once"},{"content":"Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs. NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.\nA lot of the data that you could be analyzing is unstructured data and contains human-readable text. Before you can analyze that data programmatically, you first need to preprocess it. In this tutorial, you’ll take your first look at the kinds of text preprocessing tasks you can do with NLTK so that you’ll be ready to apply them in future projects. You’ll also see how to do some basic text analysis and create visualizations.\nIf you’re familiar with the basics of using Python and would like to get your feet wet with some NLP, then you’ve come to the right place.\nBy the end of this tutorial, you’ll know how to:\nFind text to analyze Preprocess your text for analysis Analyze your text Create visualizations based on your analysis Let’s get Pythoning! ","permalink":"https://omers.github.io/docs/ai/python-nlp-libraries/","summary":"Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs. NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.\nA lot of the data that you could be analyzing is unstructured data and contains human-readable text. Before you can analyze that data programmatically, you first need to preprocess it. In this tutorial, you’ll take your first look at the kinds of text preprocessing tasks you can do with NLTK so that you’ll be ready to apply them in future projects.","title":"Python Nlp Libraries"},{"content":"Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.\n","permalink":"https://omers.github.io/docs/ai/slearn/","summary":"Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.","title":"Python Scikit Learn"}]